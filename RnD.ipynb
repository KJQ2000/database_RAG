{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd557844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’Ž Jewelry Inventory SQL Generator (type 'exit' to quit)\n",
      "\n",
      "User's question:\n",
      "\n",
      "what is the total stock weight I ahve?\n",
      "\n",
      "Generated SQL query:\n",
      "SELECT SUM(stk_weight) AS total_stock_weight FROM STOCK;\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from constant import *\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Initialize ChatOpenAI with GPT-4o-mini\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=512,\n",
    "    verbose=False,\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "# Load your dictionary file (table & column descriptions)\n",
    "def load_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Prepare prompt templates\n",
    "system_template = \"\"\"\n",
    "You are a PostgreSQL expert for a jewelry store.\n",
    "Given the database schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "And the meaning of each table and column:\n",
    "\n",
    "{dictionary}\n",
    "\n",
    "Generate ONLY a valid PostgreSQL SELECT SQL query to answer the user question.\n",
    "Do not add explanations or markdown, just output the SQL.\n",
    "If you are not sure about the question, just output 'I am not sure on this question.'\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{user_question}\"\n",
    "\n",
    "def build_prompt(schema: str, dictionary: str, user_question: str):\n",
    "    system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_msg = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "    return prompt.format_prompt(schema=schema, dictionary=dictionary, user_question=user_question).to_messages()\n",
    "\n",
    "def generate_sql(user_question, schema, dictionary):\n",
    "    messages = build_prompt(schema, dictionary, user_question)\n",
    "    response = llm(messages)\n",
    "    return response.content\n",
    "\n",
    "schema_str = SCHEMA\n",
    "dictionary_str = load_file(DICT_DIR)\n",
    "\n",
    "print(\"ðŸ’Ž Jewelry Inventory SQL Generator (type 'exit' to quit)\")\n",
    "\n",
    "while True:\n",
    "    user_question = input(\"\\nAsk your question: \").strip()\n",
    "    if user_question.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    print(\"\\nUser's question:\\n\")\n",
    "    print(user_question)\n",
    "\n",
    "    sql = generate_sql(user_question, schema_str, dictionary_str)\n",
    "    print(\"\\nGenerated SQL query:\\n\" + sql)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfef1d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’Ž Jewelry Inventory Question Answering (type 'exit' to quit)\n",
      "\n",
      "User's question:\n",
      " è¯·åˆ—å‡ºæ‰€æœ‰å®¢æˆ·ï¼ˆCustomerï¼‰çš„å§“åå’Œè”ç³»æ–¹å¼ï¼Œä»¥åŠä»–ä»¬æœ€è¿‘ä¸€æ¬¡çš„é¢„è®¢ï¼ˆBookingï¼‰æ—¥æœŸå’Œè¯¥é¢„è®¢çš„æ€»ä»·ï¼ˆbook_priceï¼‰ã€‚å¦‚æžœå®¢æˆ·æ²¡æœ‰é¢„è®¢ï¼Œåˆ™æ˜¾ç¤ºé¢„è®¢ä¿¡æ¯ä¸ºç©ºã€‚\n",
      "\n",
      "Generated SQL query:\n",
      " SELECT c.cust_name, c.cust_phone_number, c.cust_email_address, b.book_date, b.book_price\n",
      "FROM konghin.customer c\n",
      "LEFT JOIN konghin.booking b ON c.cust_id = b.book_cust_id;\n",
      "\n",
      "Final Answer:\n",
      " æ ¹æ®æŸ¥è¯¢ç»“æžœï¼Œä»¥ä¸‹æ˜¯æ‰€æœ‰å®¢æˆ·çš„å§“åå’Œè”ç³»æ–¹å¼ï¼Œä»¥åŠä»–ä»¬æœ€è¿‘ä¸€æ¬¡çš„é¢„è®¢æ—¥æœŸå’Œè¯¥é¢„è®¢çš„æ€»ä»·ï¼š\n",
      "\n",
      "| å§“å         | è”ç³»ç”µè¯      | ç”µå­é‚®ä»¶                   | æœ€è¿‘é¢„è®¢æ—¥æœŸ  | æ€»ä»·     |\n",
      "|--------------|---------------|----------------------------|---------------|----------|\n",
      "| Kuan         | 012           | 213@gmail.com              | 2025-02-23    | 1000.00  |\n",
      "| test         | 554-1234      | john.doe@example.com       | 2024-12-12    | 0.00     |\n",
      "| test 2      | 555-8765      | alice.johnson@example.com  | 2024-12-12    | 80.00    |\n",
      "| test 3      | 555-4321      | bob.brown@example.com      | ç©º            | ç©º       |\n",
      "| test 1      | 555-5678      | jane.smith@example.com     | ç©º            | ç©º       |\n",
      "\n",
      "å¦‚æžœå®¢æˆ·æ²¡æœ‰é¢„è®¢ï¼Œåˆ™æ˜¾ç¤ºé¢„è®¢ä¿¡æ¯ä¸ºç©ºã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import logging\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from constant import *\n",
    "\n",
    "# ====== LOAD ENVIRONMENT ======\n",
    "load_dotenv()\n",
    "\n",
    "# ====== LOGGING SETUP ======\n",
    "log_file = \"db_query.log\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# ====== SIMPLE DATABASE CLASS ======\n",
    "class Database: \n",
    "    # def __init__(self, database_url: str):\n",
    "    def __init__(self, host: str,port: str,database: str,user: str,password: str):\n",
    "        # self.database_url = database_url\n",
    "        # self.conn = psycopg2.connect(self.database_url)\n",
    "        self.conn = psycopg2.connect(host=host,port=port,database=database,user=user,password=password)\n",
    "        # self.cursor = self.conn.cursor()\n",
    "        self.cursor = None\n",
    "        self.schema = 'konghin'\n",
    "        self.conn.autocommit = False\n",
    "\n",
    "        \n",
    "    def select_raw(self, query: str, params: tuple = None, js: bool = False):\n",
    "        \"\"\"\n",
    "        Executes a raw SQL query with optional parameters.\n",
    "\n",
    "        Args:\n",
    "            query (str): The SQL query to execute.\n",
    "            params (tuple, optional): Parameters to safely substitute into the query.\n",
    "            js (bool, optional): If True, returns the result as a JSON string.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame or str: DataFrame of results or JSON if js=True.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # self.refresh_connection()\n",
    "            \n",
    "            if self.cursor is None or self.cursor.closed:\n",
    "                self.cursor = self.conn.cursor()\n",
    "            \n",
    "            self.cursor.execute(query, params)\n",
    "            results = self.cursor.fetchall()\n",
    "            colnames = [desc[0] for desc in self.cursor.description]\n",
    "\n",
    "            df = pd.DataFrame(results, columns=colnames)\n",
    "\n",
    "            logging.info(f\"Successfully executed query: {query}\")\n",
    "\n",
    "            if js:\n",
    "                return df.to_json(orient='records', date_format='iso')\n",
    "            return df\n",
    "\n",
    "        except psycopg2.Error as e:\n",
    "            logging.error(f\"Database error: {e.pgcode} - {e.pgerror}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Query: {query.as_string(self.conn)}\")\n",
    "            logging.error(f\"Unexpected error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'cursor') and self.cursor:\n",
    "            self.cursor.close()\n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "# ====== LOAD DICTIONARY FILE ======\n",
    "def load_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# ====== LLM SETUP ======\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=512,\n",
    "    verbose=False,\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "# ====== PROMPT TEMPLATES ======\n",
    "system_template = \"\"\"\n",
    "You are a PostgreSQL expert for a jewelry store.\n",
    "Given the database schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "And the meaning of each table and column:\n",
    "\n",
    "{dictionary}\n",
    "\n",
    "Generate ONLY a valid PostgreSQL SELECT SQL query to answer the user question.\n",
    "pls add schema name before table name. Example: SELECT * FROM konghin.stock.\n",
    "Do NOT use double quotes (\"\") around schema, table names, or column names.\n",
    "Use lowercase for schema and table names.\n",
    "Do not add explanations or markdown, just output the SQL.\n",
    "If you are not sure about the question, just output 'I am not sure on this question.'\n",
    "\"\"\"\n",
    "human_template = \"{user_question}\"\n",
    "\n",
    "def build_prompt(schema: str, dictionary: str, user_question: str):\n",
    "    system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_msg = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "    return prompt.format_prompt(schema=schema, dictionary=dictionary, user_question=user_question).to_messages()\n",
    "\n",
    "def generate_sql(user_question, schema, dictionary):\n",
    "    messages = build_prompt(schema, dictionary, user_question)\n",
    "    response = llm(messages)\n",
    "    return response.content\n",
    "\n",
    "# ====== FUNCTION TO ANSWER QUESTIONS WITH DATA ======\n",
    "def answer_with_data(df: pd.DataFrame, user_question: str):\n",
    "    \"\"\"\n",
    "    Pass the DataFrame back to the LLM to answer the original question.\n",
    "    \"\"\"\n",
    "    data_str = df.to_csv(index=False)\n",
    "    analysis_prompt = f\"\"\"\n",
    "    You are a data analyst for a jewelry store. \n",
    "    The user asked: \"{user_question}\"\n",
    "    Here is the query result:\n",
    "    {data_str}\n",
    "\n",
    "    Based on this data, provide a concise and accurate answer.\n",
    "    If user ask in mandarin, pls reply in mandarin.\n",
    "    \"\"\"\n",
    "    messages = [HumanMessagePromptTemplate.from_template(analysis_prompt).format()]\n",
    "    response = llm(messages)\n",
    "    return response.content\n",
    "\n",
    "# ====== MAIN PROGRAM ======\n",
    "if __name__ == \"__main__\":\n",
    "    schema_str = SCHEMA\n",
    "    dictionary_str = load_file(DICT_DIR)\n",
    "\n",
    "    db = Database(\n",
    "        host=os.environ[\"HOST\"],\n",
    "        port=os.environ[\"PORT\"],\n",
    "        database=os.environ[\"DATABASE\"],\n",
    "        user=os.environ[\"USER\"],\n",
    "        password=os.environ[\"PASSWORD\"]\n",
    "        )\n",
    "\n",
    "    print(\"ðŸ’Ž Jewelry Inventory Question Answering (type 'exit' to quit)\")\n",
    "    while True:\n",
    "        user_question = input(\"\\nAsk your question: \").strip()\n",
    "        if user_question.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "\n",
    "        print(\"\\nUser's question:\\n\", user_question)\n",
    "\n",
    "        # Step 1: Generate SQL\n",
    "        sql_query = generate_sql(user_question, schema_str, dictionary_str)\n",
    "        print(\"\\nGenerated SQL query:\\n\", sql_query)\n",
    "\n",
    "        if sql_query.strip().lower() == \"i am not sure on this question.\":\n",
    "            print(\"LLM could not generate a confident SQL query.\")\n",
    "            continue\n",
    "\n",
    "        # Step 2: Run SQL on Database\n",
    "        df = db.select_raw(sql_query)\n",
    "        if df is None or df.empty:\n",
    "            print(\"No results found or query error.\")\n",
    "            continue\n",
    "\n",
    "        # Step 3: Pass data back to LLM for final answer\n",
    "        final_answer = answer_with_data(df, user_question)\n",
    "        print(\"\\nFinal Answer:\\n\", final_answer)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbbfb8",
   "metadata": {},
   "source": [
    "## Intent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3939a752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keong\\AppData\\Local\\Temp\\ipykernel_2021336\\3671568503.py:29: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  intent_llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "from src.shared.constant import *\n",
    "\n",
    "INTENT_SYSTEM_PROMPT = \"\"\"\n",
    "  You are an intent classification engine for a jewelry store chatbot.\n",
    "  \n",
    "  Classify the user's question into exactly ONE of the following intents:\n",
    "  \n",
    "  - general_knowledge\n",
    "  - database_query\n",
    "  - store_info\n",
    "  - unclear\n",
    "  \n",
    "  Rules:\n",
    "    - If question asks for numbers, counts, sales, stock, transactions â†’ database_query\n",
    "    - If question asks about return, exchange, warranty, policy â†’ store_policy\n",
    "    - If question asks about the store background, history, brand â†’ store_info\n",
    "    - If question is general world knowledge â†’ general_knowledge\n",
    "    - If unsure â†’ unclear\n",
    "  \n",
    "  Respond with ONLY the intent label.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "intent_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=10,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "def classify_intent(user_question: str) -> str:\n",
    "    messages = [\n",
    "        SystemMessage(content=INTENT_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=user_question)\n",
    "    ]\n",
    "    response = intent_llm(messages)\n",
    "    return response.content.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207557eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_knowledge\n",
      "store_info\n",
      "database_query\n",
      "unclear\n"
     ]
    }
   ],
   "source": [
    "gk_query = \"Who invented the light bulb?\"\n",
    "si_query = \"Where is your store located?\"\n",
    "db_query = \"Is item #12345 available for purchase?\"\n",
    "unclear_query = \"What about that thing?\"\n",
    "result1 = classify_intent(gk_query)\n",
    "print(result1)\n",
    "result2 = classify_intent(si_query)\n",
    "print(result2)\n",
    "result3 = classify_intent(db_query)\n",
    "print(result3)\n",
    "result4 = classify_intent(unclear_query)\n",
    "print(result4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RnD_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
